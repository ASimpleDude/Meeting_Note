# ============================================================
# ğŸ“ api/services/chat_service.py
# ============================================================
import logging
import numpy as np
import chromadb
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_exception_type
from openai import AzureOpenAI, APIError, RateLimitError, APITimeoutError
from sentence_transformers import SentenceTransformer, CrossEncoder

from api.config.config import (
    AZURE_OPENAI_API_KEY,
    AZURE_OPENAI_API_VERSION,
    AZURE_OPENAI_ENDPOINT,
)
from api.services.moderation_service import moderate_input

# ============================================================
# âš™ï¸ Setup Logging
# ============================================================
logger = logging.getLogger(__name__)

# ============================================================
# ğŸ§  ChromaDB Client
# ============================================================
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="chat_memory")

# ============================================================
# ğŸ”§ Embedding & Reranker Models (táº£i 1 láº§n, cache láº¡i)
# ============================================================
embedder = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")
reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")

# ============================================================
# ğŸ¤– Azure OpenAI Client
# ============================================================
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
)

# ============================================================
# ğŸ§© Embedding Helper
# ============================================================
def get_embedding(text: str):
    """Táº¡o vector embedding tá»« text báº±ng SentenceTransformer."""
    return embedder.encode(text, convert_to_numpy=True).tolist()

# ============================================================
# ğŸ’¾ LÆ°u há»™i thoáº¡i vÃ o ChromaDB
# ============================================================
def save_to_chroma(session_id: str, user_message: str, assistant_reply: str):
    """LÆ°u 1 lÆ°á»£t há»™i thoáº¡i vÃ o ChromaDB."""
    text = f"[{session_id}] User: {user_message}\nAssistant: {assistant_reply}"
    embedding = get_embedding(text)
    all_ids = collection.get()["ids"]
    next_id = f"{session_id}_{len(all_ids)}"

    collection.add(
        documents=[text],
        embeddings=[embedding],
        metadatas=[{"session_id": session_id}],
        ids=[next_id],
    )
    logger.info(f"ğŸ’¾ Saved conversation to Chroma (ID: {next_id})")

# ============================================================
# ğŸ” TÃ¬m kiáº¿m thÃ´ng tin tá»« trÃ­ nhá»› (ChromaDB + Reranker)
# ============================================================
def search_memory(session_id: str, query: str, top_k: int = 5, threshold: float = 0.7):
    """TÃ¬m kiáº¿m ná»™i dung liÃªn quan trong cÃ¹ng session báº±ng embedding + reranker."""
    query_emb = get_embedding(query)

    # 1ï¸âƒ£ Vector Search (láº¥y sÆ¡ bá»™)
    results = collection.query(
        query_embeddings=[query_emb],
        n_results=top_k,
        where={"session_id": session_id},
    )

    if not results or not results["documents"] or not results["documents"][0]:
        logger.info("ğŸ•³ KhÃ´ng cÃ³ káº¿t quáº£ trong Chroma.")
        return ""

    candidate_docs = results["documents"][0]

    # 2ï¸âƒ£ Rerank báº±ng CrossEncoder
    pairs = [[query, doc] for doc in candidate_docs]
    scores = reranker.predict(pairs)

    sorted_indices = np.argsort(scores)[::-1]
    best_doc = candidate_docs[sorted_indices[0]]
    best_score = scores[sorted_indices[0]]

    logger.info(f"ğŸ” Reranker top score: {best_score:.3f}")

    if best_score >= threshold:
        logger.info(f"âœ… Found relevant memory (score={best_score:.3f})")
        return best_doc
    else:
        logger.info(f"âš ï¸ No confident match (score={best_score:.3f})")
        return ""

# ============================================================
# ğŸ” Retry Wrapper cho Azure API
# ============================================================
@retry(
    retry=retry_if_exception_type((RateLimitError, APIError, APITimeoutError)),
    wait=wait_random_exponential(min=1, max=30),
    stop=stop_after_attempt(3),
)
def _call_azure_openai(messages: list):
    """Gá»i Azure OpenAI ChatCompletion."""
    logger.info("ğŸ”„ Gá»­i request Ä‘áº¿n Azure OpenAI...")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.3,
        max_tokens=800,
        timeout=30,
    )
    logger.info("âœ… Nháº­n pháº£n há»“i thÃ nh cÃ´ng tá»« Azure OpenAI.")
    return response

# ============================================================
# ğŸ’¬ HÃ m chÃ­nh: Gá»i Azure OpenAI, káº¿t há»£p vá»›i Chroma Memory
# ============================================================
def generate_summary(messages: list, user_input: str = None, memory_context: str = None) -> str:
    """
    Gá»i Azure OpenAI Ä‘á»ƒ sinh pháº£n há»“i.
    Náº¿u cÃ³ memory_context thÃ¬ append vÃ o prompt trÆ°á»›c khi gá»­i.
    """
    try:
        user_message = user_input or messages[-1]["content"]

        # ThÃªm trÃ­ nhá»› náº¿u cÃ³
        if memory_context:
            user_message += f"\n\nDÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin liÃªn quan tá»« cÃ¡c láº§n trao Ä‘á»•i trÆ°á»›c:\n{memory_context}\n"

        temp_messages = messages.copy()
        temp_messages[-1]["content"] = user_message

        # # Báº­t láº¡i khi cáº§n kiá»ƒm duyá»‡t
        # if not moderate_input(user_message):
        #     return "ğŸš« Ná»™i dung bá»‹ tá»« chá»‘i â€” vui lÃ²ng khÃ´ng gá»­i dá»¯ liá»‡u nháº¡y cáº£m."

        response = _call_azure_openai(temp_messages)
        if not response or not response.choices:
            return "âš ï¸ KhÃ´ng cÃ³ pháº£n há»“i tá»« mÃ´ hÃ¬nh."

        reply = response.choices[0].message.content.strip()
        logger.info("âœ… Model tráº£ vá» pháº£n há»“i há»£p lá»‡.")
        return reply

    except Exception as e:
        logger.exception(f"âŒ Lá»—i khi gá»i Azure OpenAI: {e}")
        return "âš ï¸ Lá»—i khi xá»­ lÃ½ yÃªu cáº§u tá»« mÃ´ hÃ¬nh."
