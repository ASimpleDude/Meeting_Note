from sentence_transformers import SentenceTransformer
from openai import AzureOpenAI, APIError, RateLimitError, APITimeoutError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_exception_type
from api.config.config import (
    AZURE_OPENAI_API_KEY,
    AZURE_OPENAI_API_VERSION,
    AZURE_OPENAI_ENDPOINT,
)
from api.services import chat_tts
from api.services.moderation_service import moderate_input
import chromadb
import logging

logger = logging.getLogger(__name__)

# ============================================================
# ğŸ”§ Khá»Ÿi táº¡o client Azure OpenAI
# ============================================================
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
)

# ============================================================
# ğŸ§  Khá»Ÿi táº¡o model embedding (local)
# ============================================================
logger.info("ğŸ§  Loading local embedding model (all-MiniLM-L6-v2)...")
embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
logger.info("âœ… Embedding model loaded successfully.")

# ============================================================
# ğŸ’¾ Káº¿t ná»‘i ChromaDB
# ============================================================
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="chat_memory")

# ============================================================
# ğŸ”¹ Táº¡o embedding vector
# ============================================================
def get_embedding(text: str):
    """Sinh embedding vector tá»« text."""
    return embedding_model.encode([text])[0].tolist()

# ============================================================
# ğŸ’¾ LÆ°u há»™i thoáº¡i vÃ o ChromaDB
# ============================================================
def save_to_chroma(session_id: str, user_message: str, assistant_reply: str):
    """
    LÆ°u há»™i thoáº¡i (user + assistant) vÃ o ChromaDB Ä‘á»ƒ táº¡o trÃ­ nhá»› dÃ i háº¡n.
    """
    try:
        text = f"[{session_id}] User: {user_message}\nAssistant: {assistant_reply}"
        embedding = get_embedding(text)

        collection.add(
            documents=[text],
            embeddings=[embedding],
            ids=[f"{session_id}_{len(collection.get()['ids'])}"]
        )
        logger.info(f"ğŸ§  ÄÃ£ lÆ°u há»™i thoáº¡i cá»§a session {session_id} vÃ o ChromaDB.")
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi lÆ°u vÃ o ChromaDB: {e}")

# ============================================================
# ğŸ” Truy váº¥n trÃ­ nhá»› liÃªn quan
# ============================================================
def search_memory(session_id: str, query: str, top_k: int = 3):
    """
    TÃ¬m cÃ¡c Ä‘oáº¡n há»™i thoáº¡i tÆ°Æ¡ng tá»± nháº¥t trong ChromaDB.
    """
    try:
        query_emb = get_embedding(query)
        results = collection.query(
            query_embeddings=[query_emb],
            n_results=top_k,
        )
        if results.get("documents"):
            docs = [doc for docs in results["documents"] for doc in docs]
            return "\n".join(docs)
        return ""
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi truy váº¥n ChromaDB: {e}")
        return ""

# ============================================================
# âš™ï¸ Gá»i Azure OpenAI (cÃ³ retry)
# ============================================================
@retry(
    retry=retry_if_exception_type((RateLimitError, APIError, APITimeoutError)),
    wait=wait_random_exponential(min=1, max=30),
    stop=stop_after_attempt(3)
)
def _call_azure_openai(messages: list, tts: bool = False, id: str = ""):
    """Internal helper â€” gá»i API Azure OpenAI."""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.3,
        max_tokens=800,
        timeout=30,
    )

    if tts:
        chat_tts.save_audio_to_file(response.choices[0].message.content, "api/artifacts/audio/" + id + ".wav");

    return response

# ============================================================
# ğŸ§¾ HÃ m chÃ­nh: Gá»i GPT + sá»­ dá»¥ng Chroma memory
# ============================================================

def generate_summary(messages: list, user_input: str = None, memory_context: str = None, tts: bool = False, ss_id: str = "") -> str:
    """
    Gá»i Azure OpenAI vÃ  tráº£ vá» chuá»—i text.
    GhÃ©p thÃªm pháº§n memory_context náº¿u cÃ³.
    """
    try:
        user_message = user_input or messages[-1]["content"]

        if memory_context:
            user_message += f"\n\nDÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin liÃªn quan tá»« trÃ­ nhá»› trÆ°á»›c Ä‘Ã³:\n{memory_context}\n"

        temp_messages = messages.copy()
        temp_messages[-1]["content"] = user_message

        # if not moderate_input(user_message):
        #     return "ğŸš« Ná»™i dung bá»‹ tá»« chá»‘i â€” vui lÃ²ng khÃ´ng gá»­i dá»¯ liá»‡u nháº¡y cáº£m."

        response = _call_azure_openai(messages, tts, ss_id)

        if not response or not response.choices:
            return "âš ï¸ KhÃ´ng cÃ³ pháº£n há»“i tá»« mÃ´ hÃ¬nh."

        raw_output = response.choices[0].message.content.strip()
        logger.info("âœ… Model tráº£ vá» output.")
        return raw_output

    except Exception as e:
        logger.exception("âŒ Lá»—i khi gá»i Azure OpenAI: %s", e)
        return "âš ï¸ Lá»—i khi gá»i Azure OpenAI."