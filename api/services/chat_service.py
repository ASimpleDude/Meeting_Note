# ============================================================
# ğŸ“ api/services/chat_service.py
# ============================================================

import logging
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_exception_type
from openai import AzureOpenAI, APIError, RateLimitError, APITimeoutError
from api.config.config import (
    AZURE_OPENAI_API_KEY,
    AZURE_OPENAI_API_VERSION,
    AZURE_OPENAI_ENDPOINT,
)
from api.services.moderation_service import moderate_input


# ============================================================
# âš™ï¸ Cáº¥u hÃ¬nh logging
# ============================================================
logger = logging.getLogger(__name__)


# ============================================================
# ğŸ§  Khá»Ÿi táº¡o cÃ¡c client vÃ  model
# ============================================================
# Client Azure OpenAI (dÃ¹ng Ä‘á»ƒ sinh pháº£n há»“i há»™i thoáº¡i)
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
)

# ============================================================
# ğŸ” HÃ m gá»i Azure OpenAI (cÃ³ retry tá»± Ä‘á»™ng)
# ============================================================
@retry(
    retry=retry_if_exception_type((RateLimitError, APIError, APITimeoutError)),
    wait=wait_random_exponential(min=1, max=30),
    stop=stop_after_attempt(3),
)
def _call_azure_openai(messages: list):
    """
    Gá»­i yÃªu cáº§u Ä‘áº¿n Azure OpenAI Ä‘á»ƒ sinh pháº£n há»“i há»™i thoáº¡i.
    CÃ³ cÆ¡ cháº¿ retry khi bá»‹ lá»—i táº¡m thá»i (RateLimit, Timeout, APIError).
    """
    logger.info("Gá»­i request Ä‘áº¿n Azure OpenAI...")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.3,
        max_tokens=800,
        timeout=30,
    )
    logger.info("Nháº­n pháº£n há»“i thÃ nh cÃ´ng tá»« Azure OpenAI.")
    return response


# ============================================================
# ğŸ’¬ HÃ m chÃ­nh: Sinh pháº£n há»“i há»™i thoáº¡i (káº¿t há»£p memory)
# ============================================================
def generate_summary(messages: list, user_input: str = None, memory_context: str = None) -> str:
    """
    Sinh pháº£n há»“i há»™i thoáº¡i tá»« Azure OpenAI.
    Náº¿u cÃ³ 'memory_context' thÃ¬ ná»‘i thÃªm vÃ o prompt Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh.
    """
    try:
        user_message = user_input or messages[-1]["content"]

        # ThÃªm pháº§n trÃ­ nhá»› trÆ°á»›c Ä‘Ã³ náº¿u cÃ³
        if memory_context:
            user_message += f"\n\nThÃ´ng tin liÃªn quan tá»« cÃ¡c láº§n trao Ä‘á»•i trÆ°á»›c:\n{memory_context}\n"

        temp_messages = messages.copy()
        temp_messages[-1]["content"] = user_message

        # (Tuá»³ chá»n) Kiá»ƒm duyá»‡t ná»™i dung ngÆ°á»i dÃ¹ng
        # if not moderate_input(user_message):
        #     return "Ná»™i dung bá»‹ tá»« chá»‘i â€” vui lÃ²ng khÃ´ng gá»­i dá»¯ liá»‡u nháº¡y cáº£m."

        response = _call_azure_openai(temp_messages)
        if not response or not response.choices:
            return "KhÃ´ng cÃ³ pháº£n há»“i tá»« mÃ´ hÃ¬nh."

        reply = response.choices[0].message.content.strip()
        logger.info("Model tráº£ vá» pháº£n há»“i há»£p lá»‡.")
        return reply

    except Exception as e:
        logger.exception(f"Lá»—i khi gá»i Azure OpenAI: {e}")
        return "ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ yÃªu cáº§u tá»« mÃ´ hÃ¬nh."
